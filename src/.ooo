#include "frame_combiner.hpp"
#include <algorithm>
#include <filesystem>
#include <iostream>
#include <libavcodec/packet.h>
#include <libswscale/swscale.h>
#include <stdexcept>
#include <string>
#include <vector>

extern "C" {
#include <libavcodec/avcodec.h>
#include <libavformat/avformat.h>
#include <libswscale/swscale.h>
}

FrameCombiner::FrameCombiner(const std::string &output_dir)
    : output_dir(output_dir), frames() {
  // Step 1: Open the output_dir and check if photo is valid
  std::vector<std::string> png_files;

  for (const auto &entry : std::filesystem::directory_iterator(output_dir)) {
    if (entry.is_regular_file() && entry.path().extension() == ".png") {
      png_files.push_back(entry.path().filename().string());
    }
  }

  std::sort(png_files.begin(), png_files.end());

  // Step 2: Put all the png's into the frames vector as AVFrames
  for (const auto &png_file : png_files) {
    // Open the PNG file
    std::string file_path = output_dir + "/" + png_file;
    AVFormatContext *format_context = nullptr;
    if (avformat_open_input(&format_context, file_path.c_str(), nullptr,
                            nullptr) != 0) {
      throw std::runtime_error("Failed to open input file: " + file_path);
    }

    // Find Stream Information
    if (avformat_find_stream_info(format_context, nullptr) < 0) {
      avformat_close_input(
          &format_context); // Cleanup and close the format context
      throw std::runtime_error("Failed to find stream information for file: " +
                               file_path);
    }

    // Find the Video Stream
    int video_stream_index = av_find_best_stream(
        format_context, AVMEDIA_TYPE_VIDEO, -1, -1, nullptr, 0);
    if (video_stream_index < 0) {
      avformat_close_input(
          &format_context); // Cleanup and close the format context
      throw std::runtime_error("Failed to find video stream for file: " +
                               file_path);
    }

    AVCodecParameters *codec_parameters =
        format_context->streams[video_stream_index]->codecpar;

    // Allocate an AVFrame and AVPacket
    AVCodec *codec =
        const_cast<AVCodec *>(avcodec_find_decoder(codec_parameters->codec_id));
    AVCodecContext *codec_context = avcodec_alloc_context3(codec);
    if (avcodec_parameters_to_context(codec_context, codec_parameters) < 0) {
      avformat_close_input(
          &format_context); // Cleanup and close the format context
      throw std::runtime_error(
          "Failed to copy codec parameters to codec context for file: " +
          file_path);
    }
    if (avcodec_open2(codec_context, codec, nullptr) < 0) {
      avcodec_free_context(
          &codec_context); // Cleanup and free the codec context
      avformat_close_input(
          &format_context); // Cleanup and close the format context
      throw std::runtime_error("Failed to open codec for file: " + file_path);
    }

    AVFrame *frame = av_frame_alloc(); // Allocate an AVFrame

    // Read and Decode the Frames
    AVPacket packet;
    while (av_read_frame(format_context, &packet) >= 0) {
      if (packet.stream_index == video_stream_index) {

        // Send packet to the decoder
        if (avcodec_send_packet(codec_context, &packet) < 0) {
          av_packet_unref(&packet); // Free the packet's data
          avcodec_free_context(
              &codec_context); // Cleanup and free the codec context
          avformat_close_input(
              &format_context); // Cleanup and close the format context
          throw std::runtime_error(
              "Failed to send packet for decoding for file: " + file_path);
        }

        // Receive decoded frame
        if (avcodec_receive_frame(codec_context, frame) < 0) {
          av_packet_unref(&packet); // Free the packet's data
          avcodec_free_context(
              &codec_context); // Cleanup and free the codec context
          avformat_close_input(
              &format_context); // Cleanup and close the format context
          throw std::runtime_error(
              "Failed to receive frame after decoding for file: " + file_path);
        }

        for (unsigned int i = 0; i < frames.size(); i++) {
          frame = frames[i];
          const auto &png_file = png_files[i];
          std::cout << "[DEBUG] START BLOCK" << std::endl
                    << "Frame Name: " << png_file << std::endl
                    << "Dimensions: " << frame->width << "x" << frame->height
                    << std::endl
                    << "Pixel Format: "
                    << avcodec_pix_fmt_to_codec_tag(
                           static_cast<AVPixelFormat>(frame->format))
                    << std::endl
                    << "[DEBUG] END BLOCK" << std::endl;
        }

        // Store the frame in the frames vector
        frames.push_back(frame);
      }

      av_packet_unref(&packet); // Free the packet's data
    }

    // Cleanup and close the codec and format context
    avcodec_free_context(&codec_context);
    avformat_close_input(&format_context);
  }
}

FrameCombiner::~FrameCombiner() {
  // Free the AVFrame objects in the frames vector
  for (AVFrame *frame : frames) {
    av_frame_free(&frame);
  }
}

void FrameCombiner::combine_frames(const std::string &output_video) {
//  AVFormatContext *format_ctx = nullptr;
//  AVCodecContext *codec_ctx = nullptr;
//  AVCodec *codec = nullptr;
//  AVFrame *frame = nullptr;
//  AVPacket *packet = nullptr;
//  SwsContext *sws_ctx = nullptr;
//  int ret;
//
//  try {
//    // Step 1: Initialize output video format context
//    ret = avformat_alloc_output_context2(&format_ctx, nullptr, nullptr,
//                                         output_video.c_str());
//    if (ret < 0) {
//      throw std::runtime_error("Failed to allocate output format context");
//    }
//
//    // Step 2: Find video encoder codec
//    codec = const_cast<AVCodec *>(avcodec_find_encoder(AV_CODEC_ID_H264));
//    if (!codec) {
//      throw std::runtime_error("Failed to find video encoder codec");
//    }
//
//    // Step 3: Open output video file for writing
//    ret = avio_open(&format_ctx->pb, output_video.c_str(), AVIO_FLAG_WRITE);
//    if (ret < 0) {
//      throw std::runtime_error("Failed to open output video file");
//    }
//
//    // Step 4: Create video stream and configure codec parameters
//    AVStream *stream = avformat_new_stream(format_ctx, codec);
//    if (!stream) {
//
//      throw std::runtime_error("Failed to create video stream");
//    }
//
//    codec_ctx = avcodec_alloc_context3(codec);
//
//    if (!codec_ctx) {
//      throw std::runtime_error("Failed to allocate codec context");
//    }
//    codec_ctx->codec_id = codec->id;
//    codec_ctx->codec_type = AVMEDIA_TYPE_VIDEO;
//
//    codec_ctx->pix_fmt = AV_PIX_FMT_YUV420P;
//    codec_ctx->width = frames[0]->width;
//    codec_ctx->height = frames[0]->height;
//    codec_ctx->time_base = {1, 25};
//
//    ret = avcodec_parameters_from_context(stream->codecpar, codec_ctx);
//
//    if (ret < 0) {
//      throw std::runtime_error("Failed to copy codec parameters to stream");
//    }
//
//    // Step 5: Write encoded packets to the output file
//    ret = avformat_write_header(format_ctx, nullptr);
//
//    if (ret < 0) {
//      throw std::runtime_error("Failed to write format header");
//    }
//
//    packet = av_packet_alloc();
//    if (!packet) {
//      throw std::runtime_error("Failed to allocate packet");
//    }
//
//    frame = av_frame_alloc();
//    if (!frame) {
//
//      throw std::runtime_error("Failed to allocate frame");
//    }
//    frame->format = codec_ctx->pix_fmt;
//    frame->width = codec_ctx->width;
//    frame->height = codec_ctx->height;
//
//    sws_ctx = sws_getContext(
//        codec_ctx->width, codec_ctx->height, AV_PIX_FMT_BGR24, codec_ctx->width,
//        codec_ctx->height, codec_ctx->pix_fmt, 0, nullptr, nullptr, nullptr);
//
//    if (!sws_ctx) {
//      throw std::runtime_error("Failed to create SwsContext");
//    }
//
//    for (AVFrame *input_frame : frames) {
//      // Convert input frame to the desired pixel format
//      sws_scale(sws_ctx, input_frame->data, input_frame->linesize, 0,
//                codec_ctx->height, frame->data, frame->linesize);
//
//      // Encode the frame and write the packet to the output file
//      ret = avcodec_send_frame(codec_ctx, frame);
//      if (ret < 0) {
//        throw std::runtime_error("Failed to send frame for encoding");
//      }
//
//      while (ret >= 0) {
//        ret = avcodec_receive_packet(codec_ctx, packet);
//        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF) {
//
//          break;
//        } else if (ret < 0) {
//          throw std::runtime_error("Error during encoding");
//        }
//
//        av_write_frame(format_ctx, packet);
//        av_packet_unref(packet);
//      }
//    }
//
//    // Step 6: Write the video stream trailer and release resources
//    ret = av_write_trailer(format_ctx);
//    if (ret < 0) {
//      throw std::runtime_error("Failed to write format trailer");
//    }
//
//    av_frame_free(&frame);
//    av_packet_free(&packet);
//    avcodec_free_context(&codec_ctx);
//    avio_close(format_ctx->pb);
//    avformat_free_context(format_ctx);
//    sws_freeContext(sws_ctx);
//  } catch (const std::exception &e) {
//    std::cerr << "Error: " << e.what() << std::endl;
//    if (frame) {
//      av_frame_free(&frame);
//    }
//
//    if (packet) {
//      av_packet_free(&packet);
//    }
//    if (codec_ctx) {
//      avcodec_free_context(&codec_ctx);
//    }
//    if (format_ctx && format_ctx->pb) {
//      avio_close(format_ctx->pb);
//    }
//
//    if (format_ctx) {
//      avformat_free_context(format_ctx);
//    }
//    if (sws_ctx) {
//      sws_freeContext(sws_ctx);
//    }
//    throw;
//  }
}
